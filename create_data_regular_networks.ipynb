{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import EoN\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEIR_network(G, tau, alpha, gamma, rho, tmax):\n",
    "    # Initialize states: S=0 (Susceptible), E=1 (Exposed), I=2 (Infected), R=3 (Recovered)\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['state'] = 0  # Start all nodes as susceptible\n",
    "\n",
    "    initial_infected = int(rho*len(G.nodes()))\n",
    "    initial_infected_nodes = random.sample(list(G.nodes()), initial_infected)\n",
    "    for node in initial_infected_nodes:\n",
    "        G.nodes[node]['state'] = 2\n",
    "\n",
    "    susceptible_count = []\n",
    "    exposed_count = []\n",
    "    infected_count = []\n",
    "    recovered_count = []\n",
    "\n",
    "    for day in range(tmax + 1):\n",
    "        new_states = {}\n",
    "\n",
    "        # Count current states\n",
    "        susceptible = sum(1 for n in G.nodes if G.nodes[n]['state'] == 0)\n",
    "        exposed = sum(1 for n in G.nodes if G.nodes[n]['state'] == 1)\n",
    "        infected = sum(1 for n in G.nodes if G.nodes[n]['state'] == 2)\n",
    "        recovered = sum(1 for n in G.nodes if G.nodes[n]['state'] == 3)\n",
    "\n",
    "        susceptible_count.append(susceptible)\n",
    "        exposed_count.append(exposed)\n",
    "        infected_count.append(infected)\n",
    "        recovered_count.append(recovered)\n",
    "\n",
    "        for node in G.nodes():\n",
    "            if G.nodes[node]['state'] == 2:\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    if G.nodes[neighbor]['state'] == 0:\n",
    "                        if random.random() < tau:\n",
    "                            new_states[neighbor] = 1\n",
    "                if random.random() < gamma:\n",
    "                    new_states[node] = 3\n",
    "\n",
    "            elif G.nodes[node]['state'] == 1:\n",
    "                if random.random() < alpha:\n",
    "                    new_states[node] = 2\n",
    "\n",
    "        for node, new_state in new_states.items():\n",
    "            G.nodes[node]['state'] = new_state\n",
    "\n",
    "    return [index for index in range(tmax + 1)], susceptible_count, exposed_count, infected_count, recovered_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for the network\n",
    "\n",
    "N = 10**5\n",
    "\n",
    "G=nx.barabasi_albert_graph(N, 5)\n",
    "#G = nx.complete_graph(N)\n",
    "#G = nx.watts_strogatz_graph(N, 8, 0.1)\n",
    "#G = nx.complete_graph(N)\n",
    "\n",
    "tmax = 250\n",
    "iterations = 50  # run 5 simulations\n",
    "tau_boundaries = np.arange(0.01, 0.06, 0.01)         # transmission rate\n",
    "gamma = 0.08  # recovery rate\n",
    "rho_boundaries = np.arange(0.005, 0.011, 0.001)     # random fraction initially infected\n",
    "alpha = 0.1 # latent period rate\n",
    "\n",
    "seed = 0\n",
    "for tau in tau_boundaries:\n",
    "    for rho in rho_boundaries:\n",
    "        print('---')\n",
    "\n",
    "\n",
    "        #fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "        #ax_beta = ax.twinx()\n",
    "        for iter in range(0, iterations):\n",
    "    # SEIR\n",
    "            t, S, E, I, R = SEIR_network(G, tau, alpha, gamma, rho, tmax)\n",
    "\n",
    "            S = np.array(S)\n",
    "            E = np.array(E)\n",
    "            I = np.array(I)\n",
    "            R = np.array(R)\n",
    "\n",
    "            #ax.plot(t, I, color = 'k', alpha=0.3)\n",
    "\n",
    "            # compute betas values\n",
    "            beta_values = []\n",
    "            num_days = len(t)\n",
    "            for i in range(num_days - 1):\n",
    "                if S[i] > 0 and I[i] > 0:\n",
    "                    beta = - (S[i + 1] - S[i]) / (S[i] * I[i])\n",
    "                else:\n",
    "                    beta = np.nan\n",
    "                beta_values.append(beta)\n",
    "            beta_values.append(np.nan)\n",
    "            #ax_beta.plot(beta_values, color='lightgray', alpha=0.5)\n",
    "            # store the simulation results in a dataFrame\n",
    "            df_sim = pd.DataFrame({\n",
    "            \"S\": S,\n",
    "            \"E\": E,\n",
    "            \"I\": I,\n",
    "            \"R\": R,\n",
    "            \"Beta\": beta_values\n",
    "            })\n",
    "            output_file = f\"seir_seed_{seed}.csv\"\n",
    "            df_sim.to_csv(f'data/{output_file}', index=False)\n",
    "            print(seed)\n",
    "            seed += 1 \n",
    "\n",
    "            # save the results to a csv file\n",
    "           \n",
    "        #plt.xlabel('Days')\n",
    "        #plt.ylabel('Prevalence')\n",
    "        #plt.grid()\n",
    "        #plt.show()\n",
    "\n",
    "print('END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate csv-file with value of parameters for each seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "iterations = 50  # run 5 simulations\n",
    "tau_boundaries = np.arange(0.01, 0.06, 0.01)         # transmission rate\n",
    "gamma = 0.08  # recovery rate\n",
    "rho_boundaries = np.arange(0.005, 0.011, 0.001)     # random fraction initially infected\n",
    "alpha = 0.1 # latent period rate\n",
    "seed_number = 0\n",
    "parameters = pd.DataFrame(columns = ['seed_number','tau', 'rho'])\n",
    "for tau in tau_boundaries:\n",
    "    for rho in rho_boundaries:\n",
    "        for iter in range(0, iterations):\n",
    "            parameters = pd.concat([parameters,pd.DataFrame({'seed_number':[seed_number],'tau':[tau],'rho':[rho]})],ignore_index=True)\n",
    "            seed_number += 1 \n",
    "\n",
    "# save the results to a csv file\n",
    "parameters.to_csv('data/seeds_parameters.csv', index=False)\n",
    "print('END')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split seeds numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/seeds_parameters.csv')\n",
    "X = df.drop(columns=['tau', 'rho'])\n",
    "y = df[['tau', 'rho']]\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train = X_train.sort_values(by = ['seed_number'])\n",
    "X_test = X_test.sort_values(by = ['seed_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing the seeds on train and test and generate csv-file with value of initial and finite indexies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = pd.DataFrame(columns = ['initial','finite'])\n",
    "for i, seed_number in enumerate(X_test['seed_number'].values):\n",
    "    df = pd.read_csv(f'data/seir_seed_{seed_number}.csv')\n",
    "    test_index = pd.concat([test_index, pd.DataFrame({'initial':[seed_number],'finite':[i]})],ignore_index=True)\n",
    "    df.to_csv(f'data/test/seir_seed_{i}.csv', index=False)\n",
    "test_index.to_csv('data/test/test_index.csv',index=False)\n",
    "\n",
    "train_index = pd.DataFrame(columns = ['initial','finite'])\n",
    "for i, seed_number in enumerate(X_train['seed_number'].values):\n",
    "    df = pd.read_csv(f'data/seir_seed_{seed_number}.csv')\n",
    "    train_index = pd.concat([train_index, pd.DataFrame({'initial':[seed_number],'finite':[i]})],ignore_index=True)\n",
    "    df.to_csv(f'data/train/seir_seed_{i}.csv', index=False)\n",
    "train_index.to_csv('data/train/train_index.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate csv-file with median Beta valuies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for i in range(299):\n",
    "    df = pd.read_csv(f'data/train/seir_seed_{i}.csv')\n",
    "    betas.append(df['Beta'].values)\n",
    "betas = np.array(betas)\n",
    "# Заменяем все NaN значения на 0\n",
    "betas = np.nan_to_num(betas, nan=0.0)\n",
    "# Рассчитываем среднее значение для каждой колонки\n",
    "means = betas.mean(axis=0)\n",
    "# Создаем DataFrame для сохранения в CSV\n",
    "means_df = pd.DataFrame(means, columns=['median_beta'])\n",
    "# Сохраняем в CSV файл\n",
    "means_df.to_csv('data/train/median_beta.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
